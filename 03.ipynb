{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제3장 웹 스크래핑을 통한 데이터 수집"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 오래전에 공부한 내용을 ipynb형식으로 변경한 것임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Web scraping : 웹 페이지에 게시된 데이터를 가져오는 방법\n",
    "* API 데이터 추출 : 웹 페이지가 제공하는 데이터를 가져오는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML\n",
    "* id는 고유 값을 가지며, 일반적으로 문서에서 한 번만 사용됨.\n",
    "* class는 여러번 사용됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML (eXtensivle Markup Language)\n",
    "* XML은 데이터 교환이 목적이므로, 태그가 구조 정의를 위한 목적으로 사용된다. 개발자가 태그를 직접 정의하여 쓸 수도 있다.\n",
    "* XML은 특정 운영체제나 웹 브라우저에 구속되지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON (JavaScript Object Notation)\n",
    "* XML과 유사한 목적으로 만들어졌으나, XML보다 간편하고 쉽게 데이터 해석이 가능하다.\n",
    "* JSON은 {key : value} 쌍이 차례대로 쌓여 있는 리스트 형태이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajax\n",
    "* 사용자와 서버가 정보를 주고 받는 방식 중 하나다.\n",
    "* 사용자의 요청에 따라 서버가 전체 페이지가 아닌 일부분만 보여주는 방식이며, 사용자의 요청에 따라 일부분만이 업데이트 되는 특징을 가지고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup\n",
    "* 파싱 : HTML, XML 형식의 웹 페이지 구조를 파악, 사용자가 원하는 자료 추출 과정을 말함.\n",
    "\n",
    "|Function|Explanation|\n",
    "|---|---|\n",
    "|find_all()|일치 키워드 모두 반환|\n",
    "|find()|일치 키워드 첫 번째 발견 반환|\n",
    "|prettify()|HTML 트리 구조|\n",
    "|get_text()|HTML 문자열 반환|\n",
    "|title|title 태그 전체 반환|\n",
    "|title.name|title 태그 이름 반환|\n",
    "|title.string|title 태그 문자열 반환|\n",
    "|p|p 태그 전체 요소 반환|\n",
    "|p.string|p 태그 문자열 반환|\n",
    "|p.[`class`]|p 태그 class 속성 값 반환|\n",
    "|a|a 태그 전체 요소|\n",
    "|get('href')|a 태그 url|\n",
    "|contents|하부 단위 태그 전체 요소 반환|\n",
    "|parent|상부 단위 태그 전체 요소 반환|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 국회 홈페이지에서 국회의원 이름, 코드, 사진 추출\n",
    "# 본 풀이에선 photo라는 file 생성이 선결되어 있어야 함.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Congress man current page\n",
    "url = 'https://www.assembly.go.kr/assm/memact/congressman/memCond/memCondListAjax.do?currentPage=1&rowPerPage=300'\n",
    "\n",
    "# Data requests\n",
    "req = requests.get(url)\n",
    "req.status_code\n",
    "'''\n",
    "101 : 데이터 처리 중\n",
    "200 : 서버가 성공적으로 데이터 요청 처리\n",
    "300 : 웹 페이지가 새로운 위치로 이동\n",
    "403 : 서버가 권한 부족으로 요청 거부\n",
    "404 : 해당 웹 페이지 찾을 수 없음\n",
    "500 : 서버 오류\n",
    "503 : 서버 오버 로드 혹은 서버 유지 관리를 위해 다운되었음\n",
    "'''\n",
    "req.text\n",
    "html = req.content\n",
    "\n",
    "# Data analysis\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "member_list = soup.select('.memberna_list dl dt a')\n",
    "'''\n",
    "<div class=\"memberna_list\"> 하위에 있는 일반 태그 <dl> <dt> <a>에서\n",
    "<a> 태그에 놓여 있는 모든 정보를 가져옴\n",
    "'''\n",
    "\n",
    "with open('member_list.csv', 'w') as f:\n",
    "    # 저장할 파일을 쓸 수 있는 형태(w)로 열고, 객체 f를 생성\n",
    "    csv_writer = csv.writer(f)\n",
    "\n",
    "    for member in member_list:\n",
    "        # names of congress men\n",
    "        name = member.text\n",
    "\n",
    "        # IDs of Congress\n",
    "        id_href = member['href']\n",
    "\n",
    "        pattern = re.search(r'\\d+', id_href)\n",
    "        # re.search(정규표현식, 탐색하는 대상)\n",
    "        # re.search는 해당 식의 존재 여부에 따라 True or False를 반환함\n",
    "        if pattern:\n",
    "            mem_id = pattern.group(0)\n",
    "        else:\n",
    "            mem_id = None\n",
    "        # pattern이 T면 mem_id에 넣고, F이면 None값을 넣으라는 뜻.\n",
    "\n",
    "        # Pics of Congress\n",
    "        pic = open('photo/{}.jpg'.format(mem_id),'wb')\n",
    "        request_photo =\\\n",
    "            requests.get('http://www.assembly.go.kr/photo/{}.jpg'.format(mem_id)).content\n",
    "        pic.write(request_photo)\n",
    "        csv_writer.writerow([name, mem_id])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d49c3f6d6dd49f9272b571d9fad348ab55b8c6c3f691520d74ed0af1f69c3dd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
